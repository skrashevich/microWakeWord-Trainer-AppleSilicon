#!/usr/bin/env bash
# train_microwakeword_macos.sh
# One-shot: setup (idempotent) + run pipeline on Apple Silicon (macOS).
# Usage:
#   ./train_microwakeword_macos.sh "hey_tater" 50000 100 \
#       --piper-model /path/to/voice1.onnx --piper-model /path/to/voice2.pt
#
# Or (recommended, explicit):
#   ./train_microwakeword_macos.sh --phrase "Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚ Ğ´Ğ¾Ğ¼" --lang ru --id privet_dom \
#       --piper-model /path/to/ru_voice.onnx
#
# If no --piper-model is given, we auto-download a default voice for the language.

set -euo pipefail

TARGET_PHRASE=""
MAX_TTS_SAMPLES="50000"
BATCH_SIZE="100"
LANG="auto"
SAFE_ID=""

if [[ $# -gt 0 && "$1" != --* ]]; then
  TARGET_PHRASE="$1"; shift
  if [[ $# -gt 0 && "$1" =~ ^[0-9]+$ ]]; then MAX_TTS_SAMPLES="$1"; shift; fi
  if [[ $# -gt 0 && "$1" =~ ^[0-9]+$ ]]; then BATCH_SIZE="$1"; shift; fi
fi

# Collect any --piper-model flags (repeatable)
PIPER_MODELS=()
while [[ $# -gt 0 ]]; do
  case "$1" in
    --phrase) TARGET_PHRASE="$2"; shift 2 ;;
    --id) SAFE_ID="$2"; shift 2 ;;
    --lang) LANG="$2"; shift 2 ;;
    --max-samples) MAX_TTS_SAMPLES="$2"; shift 2 ;;
    --batch-size) BATCH_SIZE="$2"; shift 2 ;;
    --piper-model) PIPER_MODELS+=("$2"); shift 2 ;;
    *) echo "Unknown arg: $1"; exit 1 ;;
  esac
done

TARGET_PHRASE="${TARGET_PHRASE:-hey_tater}"
LANG="$(echo "$LANG" | tr '[:upper:]' '[:lower:]')"

if [[ "$(uname -s)" != "Darwin" ]]; then
  echo "âŒ This script is intended for macOS (Apple Silicon)."; exit 1
fi

# â”€â”€ Ensure system deps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ! command -v brew &>/dev/null; then
  echo "âŒ Homebrew is required but not found. Install from https://brew.sh/ first."
  exit 1
fi

# Ensure Python 3.11 is present (required for the venv below)
if ! brew list python@3.11 &>/dev/null; then
  echo "ğŸ“¦ Installing python@3.11 via Homebrewâ€¦"
  brew install python@3.11
fi

PYTHON_BIN="${PYTHON_BIN:-$(brew --prefix python@3.11)/bin/python3.11}"

echo "ğŸ“¦ Ensuring ffmpeg@7 + wget are installed (via Homebrew)â€¦"

# wget first
brew list wget &>/dev/null || brew install wget

# prefer ffmpeg@7 because torchcodec wants < 8
if brew info ffmpeg@7 &>/dev/null; then
  brew list ffmpeg@7 &>/dev/null || brew install ffmpeg@7
  FFMPEG_PREFIX="$(brew --prefix ffmpeg@7)"
  echo "âœ… Using ffmpeg@7 at $FFMPEG_PREFIX"
else
  # fallback if ffmpeg@7 isnâ€™t available on this Homebrew
  brew list ffmpeg &>/dev/null || brew install ffmpeg
  FFMPEG_PREFIX="$(brew --prefix ffmpeg)"
  echo "âš ï¸ ffmpeg@7 not found; using default ffmpeg instead"
fi

# Make the chosen ffmpeg visible to torchcodec on macOS (ARM sometimes needs DYLD_*)
FFMPEG_LIB_DIR="$FFMPEG_PREFIX/lib"
if [[ -d "$FFMPEG_LIB_DIR" ]]; then
  export DYLD_FALLBACK_LIBRARY_PATH="$FFMPEG_LIB_DIR:${DYLD_FALLBACK_LIBRARY_PATH:-}"
  export DYLD_LIBRARY_PATH="$FFMPEG_LIB_DIR:${DYLD_LIBRARY_PATH:-}"
  echo "âœ… ffmpeg library path set: $FFMPEG_LIB_DIR"
else
  echo "âš ï¸ Could not find ffmpeg lib dir at $FFMPEG_LIB_DIR"
fi

# â”€â”€ venv (ARM64 + pinned stack, install once) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TF_VERSION="${TF_VERSION:-2.16.2}"
TF_METAL_VERSION="${TF_METAL_VERSION:-1.2.0}"
KERAS_VERSION="${KERAS_VERSION:-3.3.3}"
PROTOBUF_VERSION="${PROTOBUF_VERSION:-4.25.8}"
FLATBUFFERS_VERSION="${FLATBUFFERS_VERSION:-23.5.26}"
TORCH_VERSION="${TORCH_VERSION:-2.9.0}"

if [[ ! -d ".venv" ]]; then
  echo "ğŸ§ª Creating ARM64 venv with $PYTHON_BIN"
  arch -arm64 "$PYTHON_BIN" -m venv .venv
fi

# always activate (both create + reuse)
# shellcheck disable=SC1091
source .venv/bin/activate

# canonical python for the rest of the script (never rely on PATH again)
PY="$(pwd)/.venv/bin/python"
if [[ ! -x "$PY" ]]; then
  echo "âŒ venv python not found at $PY"
  exit 1
fi

if [[ ! -f ".venv/.pinned_installed" ]]; then
  echo "ğŸ§¹ Fresh venv â†’ installing pinned toolchain"
  "$PY" -m pip install -U pip setuptools wheel

  # Pinned TF/Keras stack (stable)
  "$PY" -m pip install \
    "protobuf==${PROTOBUF_VERSION}" \
    "flatbuffers==${FLATBUFFERS_VERSION}" \
    "keras==${KERAS_VERSION}" \
    "tensorflow-macos==${TF_VERSION}" \
    "tensorflow-metal==${TF_METAL_VERSION}"

  # Pinned torch stack for torchcodec / datasets audio backend
  "$PY" -m pip install "torch==${TORCH_VERSION}" torchcodec

  touch ".venv/.pinned_installed"
else
  echo "âœ… Reusing existing .venv (no upgrades)"
fi

# â”€â”€ HARD FAIL: ensure pip is the venv pip â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VENV_PREFIX="$("$PY" -c 'import sys; print(sys.prefix)')"
"$PY" -m pip -V | grep -q "$VENV_PREFIX" || {
  echo "âŒ pip is not using venv ($VENV_PREFIX)"
  "$PY" -m pip -V
  exit 1
}

# â”€â”€ Sanity prints â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "python: $PY"
echo "pip:    $("$PY" -m pip -V | awk '{print $1, $2, $3, $4, $5}')"
"$PY" - <<'PY'
import platform, sys
print("Python:", sys.version.replace("\n"," "))
print("Arch:  ", platform.machine())
PY

# â”€â”€ Ensure weâ€™re on arm64 + supported Python â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ARCH=$("$PY" -c 'import platform; print(platform.machine())')
PYVER=$("$PY" -c 'import sys; print(f"{sys.version_info.major}.{sys.version_info.minor}")')

if [[ "$ARCH" != "arm64" ]]; then
  echo "âŒ venv arch is $ARCH (needs arm64). Recreate with:"
  echo "   rm -rf .venv && arch -arm64 $PYTHON_BIN -m venv .venv"
  exit 1
fi
case "$PYVER" in
  3.10|3.11) : ;;
  *) echo "âŒ Detected Python $PYVER. Use 3.10 or 3.11 for tensorflow-macos."
     exit 1 ;;
esac

# â”€â”€ HARD FAIL: verify pinned versions (no silent drift) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"$PY" - <<PY
import sys
import tensorflow as tf
import keras
import google.protobuf
import flatbuffers

expected = {
  "tensorflow": "${TF_VERSION}",
  "keras": "${KERAS_VERSION}",
  "protobuf": "${PROTOBUF_VERSION}",
  "flatbuffers": "${FLATBUFFERS_VERSION}",
}

actual = {
  "tensorflow": tf.__version__,
  "keras": keras.__version__,
  "protobuf": google.protobuf.__version__,
  "flatbuffers": flatbuffers.__version__,
}

bad = [(k, actual[k], expected[k]) for k in expected if actual[k] != expected[k]]
if bad:
  print("âŒ Version drift detected:")
  for k,a,e in bad:
    print(f"  - {k}: {a} (expected {e})")
  print("\nFix by rebuilding venv:")
  print("  rm -rf .venv && arch -arm64 ${PYTHON_BIN} -m venv .venv && ./train_microwakeword_macos.sh ...")
  sys.exit(1)

print("âœ… Pinned ML stack verified.")
PY

# tell HF to use torch backend, not soundfile
export DATASETS_AUDIO_BACKEND=torch

# Other deps (best-effort)
"$PY" -m pip install -q "git+https://github.com/puddly/pymicro-features@puddly/minimum-cpp-version" \
                           "git+https://github.com/whatsnowplaying/audio-metadata@d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f" || true
"$PY" -m pip install -q datasets librosa scipy numpy tqdm pyyaml requests ipython jupyter || true

# microWakeWord source (editable)
if [[ ! -d "micro-wake-word" ]]; then
  echo "â¬‡ï¸ Cloning microWakeWordâ€¦"
  git clone https://github.com/TaterTotterson/micro-wake-word.git >/dev/null
else
  echo "ğŸ” Updating microWakeWordâ€¦"
  (cd micro-wake-word && git pull --ff-only origin main || true)
fi

"$PY" -m pip install -q -e ./micro-wake-word || true

# Official piper-sample-generator (replaces fork)
bash scripts_macos/get_piper_generator.sh

# â”€â”€ verify Metal GPU (optional) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"$PY" - <<'PY'
import tensorflow as tf
devs = tf.config.list_logical_devices()
print("âœ… TF logical devices:", [d.name for d in devs])
if not any(d.device_type == "GPU" for d in devs):
    print("âš ï¸  No GPU logical device detected. Will run on CPU.")
PY

# â”€â”€ decide language + safe id â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TARGET_LANG="$LANG"
if [[ "$TARGET_LANG" == "auto" ]]; then
  TARGET_LANG="$("$PY" - <<'PY' "$TARGET_PHRASE"
import re, sys
phrase = sys.argv[1] if len(sys.argv) > 1 else ""
print("ru" if re.search(r"[Ğ-Ğ¯Ğ°-ÑĞÑ‘]", phrase) else "en")
PY
)"
fi
case "$TARGET_LANG" in
  en|ru) : ;;
  *) echo "âŒ Unsupported --lang: $TARGET_LANG (use en|ru|auto)"; exit 1 ;;
esac

if [[ -z "$SAFE_ID" ]]; then
  SAFE_ID="$("$PY" - <<'PY' "$TARGET_PHRASE"
import hashlib, re, sys

phrase = sys.argv[1] if len(sys.argv) > 1 else ""
trans = {
  "Ğ°":"a","Ğ±":"b","Ğ²":"v","Ğ³":"g","Ğ´":"d","Ğµ":"e","Ñ‘":"yo","Ğ¶":"zh","Ğ·":"z","Ğ¸":"i","Ğ¹":"y",
  "Ğº":"k","Ğ»":"l","Ğ¼":"m","Ğ½":"n","Ğ¾":"o","Ğ¿":"p","Ñ€":"r","Ñ":"s","Ñ‚":"t","Ñƒ":"u","Ñ„":"f",
  "Ñ…":"kh","Ñ†":"ts","Ñ‡":"ch","Ñˆ":"sh","Ñ‰":"shch","ÑŠ":"","Ñ‹":"y","ÑŒ":"","Ñ":"e","Ñ":"yu","Ñ":"ya",
}

out = []
for ch in phrase.lower():
  if ch in trans:
    out.append(trans[ch])
  elif ch.isalnum():
    out.append(ch)
  elif ch.isspace() or ch in "-_":
    out.append("_")
  else:
    out.append("_")

slug = re.sub(r"_+", "_", "".join(out)).strip("_")
if not slug:
  h = hashlib.sha1(phrase.encode("utf-8")).hexdigest()[:8]
  slug = f"wakeword_{h}"
print(slug)
PY
)"
fi

# â”€â”€ export for inline python â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export TARGET_PHRASE MAX_TTS_SAMPLES BATCH_SIZE SAFE_ID TARGET_LANG

# â”€â”€ Ensure at least one model is provided (auto-fetch default if none) â”€â”€â”€â”€â”€â”€â”€â”€
if [[ ${#PIPER_MODELS[@]} -eq 0 ]]; then
  if [[ "$TARGET_LANG" == "ru" ]]; then
    DEFAULT_MODEL_ONNX="piper-sample-generator/models/ru_RU-dmitri-medium.onnx"
    DEFAULT_MODEL_JSON="piper-sample-generator/models/ru_RU-dmitri-medium.onnx.json"
    echo "â„¹ï¸  No --piper-model provided; using default RU voice:"
    echo "    $DEFAULT_MODEL_ONNX"
    mkdir -p "$(dirname "$DEFAULT_MODEL_ONNX")"
    if [[ ! -f "$DEFAULT_MODEL_ONNX" ]]; then
      wget -q -O "$DEFAULT_MODEL_ONNX" \
        "https://huggingface.co/rhasspy/piper-voices/resolve/main/ru/ru_RU/dmitri/medium/ru_RU-dmitri-medium.onnx"
    fi
    if [[ ! -f "$DEFAULT_MODEL_JSON" ]]; then
      wget -q -O "$DEFAULT_MODEL_JSON" \
        "https://huggingface.co/rhasspy/piper-voices/resolve/main/ru/ru_RU/dmitri/medium/ru_RU-dmitri-medium.onnx.json"
    fi
    PIPER_MODELS=("$DEFAULT_MODEL_ONNX")
  else
    DEFAULT_MODEL_PT="piper-sample-generator/models/en_US-libritts_r-medium.pt"
    echo "â„¹ï¸  No --piper-model provided; using default EN voice:"
    echo "    $DEFAULT_MODEL_PT"
    mkdir -p "$(dirname "$DEFAULT_MODEL_PT")"
    if [[ ! -f "$DEFAULT_MODEL_PT" ]]; then
      wget -q -O "$DEFAULT_MODEL_PT" \
        "https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt"
    fi
    PIPER_MODELS=("$DEFAULT_MODEL_PT")
  fi
fi

# â”€â”€ Pass models to Python via env â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PIPER_MODELS_CSV=""
if [[ ${#PIPER_MODELS[@]} -gt 0 ]]; then
  PIPER_MODELS_CSV=$(IFS=,; echo "${PIPER_MODELS[*]}")
fi
export PIPER_MODELS_CSV

# â”€â”€ (A) clean previous run artifacts (match NVIDIA/Streamlit version) â”€â”€â”€â”€â”€â”€â”€â”€
echo "ğŸ§¹ Cleaning previous run artifactsâ€¦"
rm -f  training_parameters.yaml
rm -rf trained_models
rm -rf generated_augmented_features
rm -rf generated_samples
echo "âœ… Cleanup done."

mkdir -p generated_samples

# â”€â”€ (B) bulk TTS (skip if enough files present) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
count_existing=$(find generated_samples -name '*.wav' 2>/dev/null | wc -l | tr -d ' ')
if [[ "${count_existing:-0}" -lt "$MAX_TTS_SAMPLES" ]]; then
  echo "ğŸ¤ Generating ${MAX_TTS_SAMPLES} samples for '${TARGET_PHRASE}' (batch ${BATCH_SIZE})â€¦"
  "$PY" - <<'PY'
import os, sys, shlex, subprocess

# make sure the generator is importable
if "piper-sample-generator/" not in sys.path:
    sys.path.append("piper-sample-generator/")

TARGET = os.environ["TARGET_PHRASE"]
MAX_SAMPLES = int(os.environ["MAX_TTS_SAMPLES"])
BATCH = int(os.environ["BATCH_SIZE"])
OUT_DIR = "generated_samples"

models = [m.strip() for m in os.environ.get("PIPER_MODELS_CSV","").split(",") if m.strip()]
model_flags = sum([["--model", m] for m in models], [])

# "Speed" control for Piper is length_scale; generator exposes it as --length-scales
LENGTH_SCALES = ["0.85", "0.95", "1.0", "1.05", "1.15"]

cmd = [
    sys.executable,
    "piper-sample-generator/generate_samples.py",
    TARGET,
    "--max-samples", str(MAX_SAMPLES),
    "--batch-size",  str(BATCH),
    "--output-dir",  OUT_DIR,
    "--length-scales", *LENGTH_SCALES,
    *model_flags,
]

print("CMD:", " ".join(shlex.quote(c) for c in cmd))
proc = subprocess.run(cmd, text=True)
if proc.returncode != 0:
    raise SystemExit(proc.returncode)
PY
else
  echo "âœ… Found ${count_existing} samples (>= desired); skipping TTS generation."
fi

# â”€â”€ (C) pull/prepare augmentation datasets (RIR, Audioset, FMA) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"$PY" scripts_macos/prepare_datasets.py

# â”€â”€ (D) build augmenter + spectrogram feature mmaps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"$PY" scripts_macos/make_features.py

# â”€â”€ (E) download precomputed negative spectrograms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"$PY" scripts_macos/fetch_negatives.py

# â”€â”€ (F) write training YAML (tuned for your notebook) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"$PY" scripts_macos/write_training_yaml.py

# â”€â”€ (G) train + export (Metal TF) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"$PY" -m microwakeword.model_train_eval \
  --training_config=training_parameters.yaml \
  --train 1 \
  --restore_checkpoint 1 \
  --test_tf_nonstreaming 0 \
  --test_tflite_nonstreaming 0 \
  --test_tflite_nonstreaming_quantized 0 \
  --test_tflite_streaming 0 \
  --test_tflite_streaming_quantized 1 \
  --use_weights "best_weights" \
  mixednet \
  --pointwise_filters "64,64,64,64" \
  --repeat_in_block "1,1,1,1" \
  --mixconv_kernel_sizes "[5], [7,11], [9,15], [23]" \
  --residual_connection "0,0,0,0" \
  --first_conv_filters 32 \
  --first_conv_kernel_size 5 \
  --stride 2

# â”€â”€ (H) package artifacts (name by wake word) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"$PY" - <<'PY'
import os, re, shutil, json
from pathlib import Path

target = os.environ.get("TARGET_PHRASE", "wakeword")
safe = os.environ.get("SAFE_ID") or ""
if safe:
    safe = re.sub(r'[^a-z0-9_]+', '', re.sub(r'\s+', '_', safe.lower()))
if not safe:
    safe = re.sub(r'[^a-z0-9_]+', '', re.sub(r'\s+', '_', target.lower()))
    safe = safe or "wakeword"
lang = os.environ.get("TARGET_LANG", "en")

src = Path("trained_models/wakeword/tflite_stream_state_internal_quant/stream_state_internal_quant.tflite")
dst = Path(f"{safe}.tflite")
if not src.exists():
    raise SystemExit(f"âŒ Model not found at {src}")
shutil.copy(src, dst)

meta = {
  "type": "micro",
  "wake_word": target,
  "author": "Tater Totterson",
  "website": "https://github.com/skrashevich/microWakeWord-Trainer-AppleSilicon",
  "model": f"{safe}.tflite",
  "trained_languages": [lang],
  "version": 2,
  "micro": {
    "probability_cutoff": 0.97,
    "sliding_window_size": 5,
    "feature_step_size": 10,
    "tensor_arena_size": 30000,
    "minimum_esphome_version": "2024.7.0"
  }
}
json_path = Path(f"{safe}.json")
json_path.write_text(json.dumps(meta, indent=2))

print(f"ğŸ“¦ Wrote {dst.name} and {json_path.name} (wake word: {target!r})")
PY

echo "ğŸ‰ Done."
